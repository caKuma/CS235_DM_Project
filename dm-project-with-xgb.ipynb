{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-07T23:49:44.919593Z","iopub.execute_input":"2023-11-07T23:49:44.919874Z","iopub.status.idle":"2023-11-07T23:49:45.295505Z","shell.execute_reply.started":"2023-11-07T23:49:44.919847Z","shell.execute_reply":"2023-11-07T23:49:45.294467Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dm-dataset-2/classesup.npy\n/kaggle/input/dm-dataset-2/model_dataset.csv\n/kaggle/input/dm-dataset-2/k_fold_10.json\n/kaggle/input/dm-dataset-2/classesdown.npy\n/kaggle/input/dm-dataset-2/classes.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport re\nimport optuna\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import  StandardScaler\nfrom sklearn.metrics import mean_absolute_error\n# Load the saved fold indices from the JSON file\nwith open('/kaggle/input/dm-dataset-2/k_fold_10.json', 'r') as file:\n    fold_indices = json.load(file)\n    \ndf=pd.read_csv('/kaggle/input/dm-dataset-2/model_dataset.csv')\nscore=df['score']\n    \n# Change columns names ([LightGBM] Do not support special JSON characters in feature name.)\nnew_names = {col: re.sub(r'[^A-Za-z0-9_]+', '', col) for col in df.columns}\nnew_n_list = list(new_names.values())\n# [LightGBM] Feature appears more than one time.\nnew_names = {col: f'{new_col}_{i}' if new_col in new_n_list[:i] else new_col for i, (col, new_col) in enumerate(new_names.items())}\ndf = df.rename(columns=new_names)\n\n# 'fold_indices' now contains the loaded fold indices\nY=score\nX=df.drop(columns=['id','score'])\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# optuna hyperparameter optimization\n\ndef objective(trial,X,Y):\n    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,random_state=42)\n    \n    param = {\n              'random_state': 42 ,\n            'n_estimators': 10000,\n            'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n            'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n            'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.6,0.7,0.8]),\n        'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.05,0.01,0.01]),\n        'max_depth': trial.suggest_categorical('max_depth', [10,25,30]),\n        'eta': trial.suggest_float('eta', 0.007, 0.013),\n        'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n            }\n    \n    model=xgb.XGBRegressor(predictor='gpu_predictor',\n        n_jobs=4,eval_metric=mean_absolute_error,**param) \n    model.fit(x_train,y_train, eval_set=[(x_test,y_test)],verbose=False)\n    \n    preds=model.predict(x_test)\n    \n    mae=mean_absolute_error(y_test,preds)\n    \n    return mae\n    \n# studying the parameter\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(lambda trial: objective(trial,X,Y), n_trials=15)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T23:49:45.297108Z","iopub.execute_input":"2023-11-07T23:49:45.297554Z","iopub.status.idle":"2023-11-08T00:22:42.641811Z","shell.execute_reply.started":"2023-11-07T23:49:45.297520Z","shell.execute_reply":"2023-11-08T00:22:42.640733Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[I 2023-11-07 23:49:47,841] A new study created in memory with name: no-name-1005bb72-9d8f-404a-a594-94d446f509a7\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-07 23:52:54,620] Trial 0 finished with value: 0.5353005528450012 and parameters: {'reg_alpha': 0.005436604958228731, 'reg_lambda': 0.4492973632526505, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.05, 'max_depth': 25, 'eta': 0.011261950207626305, 'gamma': 5.442512957265412}. Best is trial 0 with value: 0.5353005528450012.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-07 23:54:20,531] Trial 1 finished with value: 0.5333800156589462 and parameters: {'reg_alpha': 0.005243348077832719, 'reg_lambda': 0.27557353119421174, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 10, 'eta': 0.01180902270922582, 'gamma': 0.02273429349568457}. Best is trial 1 with value: 0.5333800156589462.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-07 23:57:00,975] Trial 2 finished with value: 0.6137861182332521 and parameters: {'reg_alpha': 0.006346746561684751, 'reg_lambda': 0.3149396799880551, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.05, 'max_depth': 25, 'eta': 0.008681711051923611, 'gamma': 158.82667913395704}. Best is trial 1 with value: 0.5333800156589462.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-07 23:58:48,423] Trial 3 finished with value: 0.7320316851380383 and parameters: {'reg_alpha': 0.005642840253160948, 'reg_lambda': 0.49969860273066313, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.01, 'max_depth': 10, 'eta': 0.01121307480171464, 'gamma': 446.40819619770144}. Best is trial 1 with value: 0.5333800156589462.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:01:23,937] Trial 4 finished with value: 0.5412185932943213 and parameters: {'reg_alpha': 0.005104411782076095, 'reg_lambda': 0.4652425944263636, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 25, 'eta': 0.009333811314795094, 'gamma': 0.0009616813192939}. Best is trial 1 with value: 0.5333800156589462.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:04:23,896] Trial 5 finished with value: 0.5317951385308857 and parameters: {'reg_alpha': 0.006506969362358647, 'reg_lambda': 0.39282704101324495, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 30, 'eta': 0.010562715842582532, 'gamma': 10.641468970175415}. Best is trial 5 with value: 0.5317951385308857.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:06:27,664] Trial 6 finished with value: 0.8198269851777235 and parameters: {'reg_alpha': 0.005068107972277118, 'reg_lambda': 0.44170152213902625, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.05, 'max_depth': 25, 'eta': 0.012501326725301826, 'gamma': 7646.813613702324}. Best is trial 5 with value: 0.5317951385308857.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:07:59,788] Trial 7 finished with value: 0.5353618404160627 and parameters: {'reg_alpha': 0.0057272344746718325, 'reg_lambda': 0.3254199433443002, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.05, 'max_depth': 10, 'eta': 0.010053704240429945, 'gamma': 0.1778498531490291}. Best is trial 5 with value: 0.5317951385308857.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:10:48,511] Trial 8 finished with value: 0.5411230265370265 and parameters: {'reg_alpha': 0.0055024377060413805, 'reg_lambda': 0.3185093114037586, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 30, 'eta': 0.011317707614134247, 'gamma': 0.0071335687710077636}. Best is trial 5 with value: 0.5317951385308857.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:12:21,826] Trial 9 finished with value: 0.5382513039507847 and parameters: {'reg_alpha': 0.006406523732946902, 'reg_lambda': 0.29374527081724966, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.05, 'max_depth': 10, 'eta': 0.00899194167839076, 'gamma': 0.00610525348100301}. Best is trial 5 with value: 0.5317951385308857.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:15:03,307] Trial 10 finished with value: 0.5356025435181282 and parameters: {'reg_alpha': 0.006897213444177469, 'reg_lambda': 0.38023762957461843, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 30, 'eta': 0.007392879393283037, 'gamma': 1.5495290547728098}. Best is trial 5 with value: 0.5317951385308857.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:17:20,767] Trial 11 finished with value: 0.5394816664066392 and parameters: {'reg_alpha': 0.006090129691302032, 'reg_lambda': 0.25876935557910896, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 30, 'eta': 0.012768161776424631, 'gamma': 0.00013905147230392945}. Best is trial 5 with value: 0.5317951385308857.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:20:00,010] Trial 12 finished with value: 0.5412588184661711 and parameters: {'reg_alpha': 0.00594214005431783, 'reg_lambda': 0.37480255264425716, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 30, 'eta': 0.010361040009836255, 'gamma': 0.05920327989237439}. Best is trial 5 with value: 0.5317951385308857.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:21:17,874] Trial 13 finished with value: 0.5282631453714872 and parameters: {'reg_alpha': 0.005267890553504806, 'reg_lambda': 0.274995940556105, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 10, 'eta': 0.01176581662520899, 'gamma': 5.460322647793291}. Best is trial 13 with value: 0.5282631453714872.\n/tmp/ipykernel_32/4294035916.py:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_alpha': trial.suggest_loguniform('reg_alpha',0.005,0.007),\n/tmp/ipykernel_32/4294035916.py:37: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'reg_lambda': trial.suggest_loguniform('reg_lambda',0.25, 0.5 ),\n/tmp/ipykernel_32/4294035916.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n[I 2023-11-08 00:22:42,634] Trial 14 finished with value: 0.5299444063472362 and parameters: {'reg_alpha': 0.005354411971821179, 'reg_lambda': 0.3530464590949511, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 10, 'eta': 0.010571810805497368, 'gamma': 6.772923653395515}. Best is trial 13 with value: 0.5282631453714872.\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 15\nBest trial: {'reg_alpha': 0.005267890553504806, 'reg_lambda': 0.274995940556105, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 10, 'eta': 0.01176581662520899, 'gamma': 5.460322647793291}\n","output_type":"stream"}]},{"cell_type":"code","source":"params=study.best_params \nparams['random_state'] = 42\nparams['n_estimators'] = 10000 \nmae=[]\n\nimport xgboost as xgb\nfor fold_number, fold_data in enumerate(fold_indices):\n    train_index = fold_data['train_indices']\n    test_index = fold_data['test_indices']\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = Y[train_index], Y[test_index]\n    model_x = xgb.XGBRegressor(predictor='gpu_predictor',\n        n_jobs=4,eval_metric=mean_absolute_error,**params )\n    valid_check = xgb.callback.EvaluationMonitor(period=10000)\n    model_x.fit(X_train,y_train, eval_set=[(X_test,y_test)] ,callbacks=[valid_check] , verbose = False )\n    mae.append(mean_absolute_error(y_test,model_x.predict(X_test)))\n    print(f'Mean absolute error is fold is {mae[-1]}')\n    \n                               \n                               ","metadata":{"execution":{"iopub.status.busy":"2023-11-08T00:31:43.957759Z","iopub.execute_input":"2023-11-08T00:31:43.958206Z","iopub.status.idle":"2023-11-08T00:46:04.637732Z","shell.execute_reply.started":"2023-11-08T00:31:43.958173Z","shell.execute_reply":"2023-11-08T00:46:04.636684Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-rmse:3.27383\tvalidation_0-mean_absolute_error:3.09753\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.68908\tvalidation_0-mean_absolute_error:0.54395\nMean absolute error is fold is 0.5439491561549877\n[0]\tvalidation_0-rmse:3.30865\tvalidation_0-mean_absolute_error:3.15467\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.66098\tvalidation_0-mean_absolute_error:0.51072\nMean absolute error is fold is 0.5107218982719699\n[0]\tvalidation_0-rmse:3.29416\tvalidation_0-mean_absolute_error:3.12392\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.65008\tvalidation_0-mean_absolute_error:0.49610\nMean absolute error is fold is 0.49610333404077694\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-rmse:3.34041\tvalidation_0-mean_absolute_error:3.16577\n[9999]\tvalidation_0-rmse:0.69803\tvalidation_0-mean_absolute_error:0.54118\nMean absolute error is fold is 0.5411760922868242\n[0]\tvalidation_0-rmse:3.28771\tvalidation_0-mean_absolute_error:3.13262\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.61623\tvalidation_0-mean_absolute_error:0.47354\nMean absolute error is fold is 0.47354286209291774\n[0]\tvalidation_0-rmse:3.34990\tvalidation_0-mean_absolute_error:3.21256\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.62731\tvalidation_0-mean_absolute_error:0.47674\nMean absolute error is fold is 0.47674272079699437\n[0]\tvalidation_0-rmse:3.38185\tvalidation_0-mean_absolute_error:3.22926\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.63770\tvalidation_0-mean_absolute_error:0.49721\nMean absolute error is fold is 0.49720516292060296\n[0]\tvalidation_0-rmse:3.44785\tvalidation_0-mean_absolute_error:3.30270\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.62936\tvalidation_0-mean_absolute_error:0.48838\nMean absolute error is fold is 0.4883750158596814\n[0]\tvalidation_0-rmse:3.35149\tvalidation_0-mean_absolute_error:3.21376\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.60520\tvalidation_0-mean_absolute_error:0.46851\nMean absolute error is fold is 0.46851005011457736\n[0]\tvalidation_0-rmse:3.38065\tvalidation_0-mean_absolute_error:3.22433\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[9999]\tvalidation_0-rmse:0.63561\tvalidation_0-mean_absolute_error:0.48721\nMean absolute error is fold is 0.48720671587843234\n","output_type":"stream"}]},{"cell_type":"code","source":"Final_mae=np.mean(mae)\nFinal_mae","metadata":{"execution":{"iopub.status.busy":"2023-11-08T01:01:25.853086Z","iopub.execute_input":"2023-11-08T01:01:25.853730Z","iopub.status.idle":"2023-11-08T01:01:25.861218Z","shell.execute_reply.started":"2023-11-08T01:01:25.853692Z","shell.execute_reply":"2023-11-08T01:01:25.860288Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0.49835330084177654"},"metadata":{}}]},{"cell_type":"markdown","source":"# Hence, the Final Mean Absolute Error is 0.49835","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}